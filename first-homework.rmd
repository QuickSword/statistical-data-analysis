---
title: "Pierwsza praca domowa - Statystyczna analiza danych"
author: Joanna Kęczkowska
date: 30.03.2021
output: html_notebook
---

Zbiór laptops.csv zawiera następujące zmienne: \
• inches – rozmiar przekątnej w calach \
• weight – waga laptopa \
• price_euros – cena laptopa w euro \
• company – producent laptopa (1 – Acer, 2 – Asus, 3 – Dell, 4 – HP, 5 – Lenovo, 6 – MSI, 7 –
Toshiba) \
• typename – typ laptopa (1 – 2w1, 2 – gaming, 3 – netbook, 4 – notebook, 5 – ultrabook, 6 – stacja
robocza) \
• ram – ilość RAM laptopa (1 – 4GB, 2 – 8GB, 3 – 16GB, 4 – 32GB) \


```{r Ładowanie danych z pliku}
dataSet <- read.csv(file = "laptops.csv", sep = ";", header = TRUE)
str(dataSet)
summary(dataSet)

```

Należy zweryfikować następujące hipotezy: \
**a)** Stosowana ilość RAM w laptopie jest zależna od jego producenta. \


**Chi-square test** sprawdza zależność między zmiennymi. \

dla danej komórki wartość oczekiwana: $e = \frac{row.sum*col.sum}{grand.total}$ \
Chi-square statistic: ${\chi}^2 = \sum \frac{(o-e)^2}{e}$, gdzie o - obserwacja, e - wartosc oczekiwana

Hipoteza zerowa $H_0$: Stosowana ilość RAM w laptopie jest  **niezależna** od jego producenta.\
Hipoteza alternatywna $H_1$: Stosowana ilość RAM w laptopie jest **zależna** od jego producenta.\

```{r Stosowana ilość RAM w laptopie jest zależna od jego producenta}
alpha <- 0.05 #5% level of significance

memory <- dataSet$ram
company <- dataSet$company


TAB <- table(company, memory)
TAB
barplot(TAB, legend = T)


```
```{r}
alpha <- 0.01

total <- sum(TAB)
sumRows <- margin.table(TAB, 1) #rows
sumCols <- margin.table(TAB,2) #columns

sumRows <- as.vector(sumRows)
sumCols <- as.vector(sumCols)

#expected observations
exp <- matrix(rep(0, 4*7), nrow=7, ncol=4)
exp[] <- 0L
for(i in 1:7) {
    exp[i, ] <- sumRows[i]*sumCols/total
}
#observations
#obs <- matrix(rep(0, 4*7), nrow=7, ncol=4)

Tab <- data.frame(TAB)
obs <- matrix(Tab[["Freq"]], nrow = 7, ncol = 4)

chi_sq <- sum((obs-exp)^2/exp) #test statistic
df <- (nrow(obs)-1)*(ncol(obs)-1) #deg of freedom
pval <- pchisq(chi_sq, df, lower.tail=FALSE)  #test of independence is always right-tailed because of the calculation of the test statistic

quantile <- qchisq(alpha, df, lower.tail = FALSE) #quantile of chi-square distribution

if(alpha > pval) {
  print("H0 rejected.")
}else {
  print("There is not enough evidence to suggest an association between RAM and company")
}
sprintf("test statistic = %f , p-value = %f, confidece interval = [-infinity, %f]", chi_sq, pval, quantile)

#chisq.test()
test <- chisq.test(TAB)
test
```
Wychodzi, że **ilość pamięci RAM zależy od producenta** (wartość statystyki testowej wpada do obszaru krytycznego oraz p-value jest mniejsze niż nasz ustalony poziom istotności).

**b)** Rozkład stosowanych pamięci RAM w notebookach HP i Lenovo jest taki sam.\

**Test istotności dla dwóch wariancji** sprawdza hipotezę, że próby pochodzą z populacji o jednakowych wariancjach.

Hipoteza zerowa $H_0$: Równe wariancje.
Hipoteza alternatywna $H_1$: Różne wariancje

```{r Rozkład stosowanych pamięci RAM w notebookach HP i Lenovo jest taki sam}
alpha <- 0.1

#independent populations
LenovoRAM <- dataSet[dataSet$company=="5", ]$ram
HPRAM <- dataSet[dataSet$company=="4", ]$ram

n <- length(LenovoRAM)
m <- length(HPRAM)

#unbiased variance estimators
unbiased_estX <- 1/(n-1)*sum((LenovoRAM-mean(LenovoRAM))^2)
unbiased_estY <- 1/(m-1)*sum((HPRAM-mean(HPRAM))^2)

#fisher's test
F <- unbiased_estX/(unbiased_estY) # Snedecor's F distribution
pval <- pf(F, n-1, m-1, lower.tail = FALSE)
quantile <- qf(alpha, n-1, m-1, lower.tail = FALSE) #right-tailed

if(alpha > pval) {
  print("H0 rejected.")
}else {
  print("There is not enough evidence to reject H_0")
}
sprintf("test statistic = %f , p-value = %f, confidece interval = [-infinity, %f]", F, pval, quantile)

#sprawdźmy
var.test(LenovoRAM, HPRAM, 1)
```

**Odrzucamy hipotezę zerową** ponieważ wartość testu wpada do obszaru krytycznego / p-value jest mniejsze niż ustalony poziom istotności.\ **Rozkład stosowanych pamięci RAM w notebookach HP i Lenovo nie jest taki sam.**\

**c)** Średnia zlogarytmowana cena notebooka Dell i HP jest równa.\

**Independent two-sample t-test** wykorzystujemy, gdy chcemy porównać dwie grupy pod względem jakiejś zmiennej ilościowej.\
Hipoteza zerowa $H_0$: Średnia zlogarytmowana cena notebooka Dell jest taka sama jak średnia zlogarytmowana cena notebooka HP.\
Hipoteza alternatywna $H_1$: Średnie zlogarytmowane ceny notebooków różnią się.\


```{r Średnia zlogarytmowana cena notebooka Dell i HP jest równa}
alpha <- 0.1

dellPrices <- dataSet[dataSet$company=="3", "price_euros"]
hpPrices <- dataSet[dataSet$company=="4", "price_euros"]

logDellPrices <- log2(dellPrices)
logHpPrices <- log2(hpPrices)

n <- length(dellPrices)
m <- length(hpPrices)

#checking assumption
assum <- var(logDellPrices) != var(logHpPrices)

#unbiased variance estimators
unbiased_estX <- 1/(n-1)*sum((logDellPrices-mean(logDellPrices))^2)
unbiased_estY <- 1/(m-1)*sum((logHpPrices-mean(logHpPrices))^2)

a <- unbiased_estX/n + unbiased_estY/m
t <- (mean(logDellPrices) - mean(logHpPrices))/sqrt(a) #test statistic

df <- a^2/(1/(n-1)*(unbiased_estX/n)^2+1/(m-1)*(unbiased_estY/m)^2) #deg of freedom

#two-tailed hypothesis
pval <- 2*pt(t, n+m-2, lower.tail = FALSE)


#confidence interval
lowerBound <- qt(alpha, n+m-2)
upperBound <- qt(1-alpha, n+m-2)

if(alpha > pval) {
  print("H0 rejected.")
}else {
  print("There is not enough evidence to reject H_0")
}
sprintf("Spełnione założenia: %s, test statistic = %f , p-value=%f, confidence interval = (%f, %f)", assum, t, pval, lowerBound, upperBound)


#t.test
t.test(logDellPrices, logHpPrices)


```

**Odrzucamy hipotezę zerową** - wartość testu wpada do obszaru krytycznego/ p-value mniejsze niż ustalony poziom istotności - na rzecz hipppotezy alternatywnej.\ **Średnie zlogarytmowane ceny notebooków różnią się.**